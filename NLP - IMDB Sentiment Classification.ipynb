{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Hussain Abbas, MSc\n",
    "# Â© 2021 Stats AI LLC \n",
    "# All Rights Reserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Verify GPU is detected and working\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe Feature Extraction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_train, ds_info = tfds.load(name=\"imdb_reviews\", split=\"train\", with_info=True, as_supervised=True)\n",
    "imdb_test = tfds.load(name=\"imdb_reviews\", split=\"test\", as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the default tokenizer settings\n",
    "tokenizer = tfds.deprecated.text.Tokenizer()\n",
    " \n",
    "vocabulary_set = set()\n",
    "MAX_TOKENS = 0\n",
    "\n",
    "for example, label in imdb_train:\n",
    "    some_tokens = tokenizer.tokenize(example.numpy())\n",
    "    if MAX_TOKENS < len(some_tokens):\n",
    "        MAX_TOKENS = len(some_tokens)\n",
    "    vocabulary_set.update(some_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93931 2525\n"
     ]
    }
   ],
   "source": [
    "imdb_encoder = tfds.deprecated.text.TokenTextEncoder(vocabulary_set, lowercase=True, tokenizer=tokenizer)\n",
    "\n",
    "vocab_size = imdb_encoder.vocab_size\n",
    "print(vocab_size, MAX_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation functions to be used with the dataset\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "def encode_pad_transform(sample):\n",
    "    encoded = imdb_encoder.encode(sample.numpy())\n",
    "    pad = sequence.pad_sequences([encoded], padding='post', maxlen=150)\n",
    "    return np.array(pad[0], dtype=np.int64)\n",
    "\n",
    "def encode_tf_fn(sample, label):\n",
    "    encoded = tf.py_function(encode_pad_transform, inp=[sample], Tout=(tf.int64))\n",
    "    encoded.set_shape([None])\n",
    "    label.set_shape([])\n",
    "    return encoded, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = imdb_train.map(encode_tf_fn,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "encoded_test = imdb_test.map(encode_tf_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib\n",
    "# import zipfile\n",
    "# import os\n",
    "\n",
    "# url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
    "# extract_dir = \"glove_embeddings\"\n",
    "\n",
    "# zip_path, _ = urllib.request.urlretrieve(url)\n",
    "# with zipfile.ZipFile(zip_path, \"r\") as f:\n",
    "#     f.extractall(extract_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir(extract_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary Size:  400000\n"
     ]
    }
   ],
   "source": [
    "dict_w2v = {}\n",
    "\n",
    "with open('glove_embeddings/glove.6B.50d.txt', 'r', encoding=\"utf8\") as file:\n",
    "    for line in file:\n",
    "        tokens = line.split()\n",
    "        word = tokens[0]\n",
    "        vector = np.array(tokens[1:], dtype=np.float32)\n",
    "        \n",
    "        if vector.shape[0] == 50:\n",
    "            dict_w2v[word] = vector\n",
    "        else:\n",
    "            print(\"There was an issue with \" + word)\n",
    "\n",
    "# let's check the vocabulary size\n",
    "print(\"Dictionary Size: \", len(dict_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "embedding_matrix = np.zeros((imdb_encoder.vocab_size, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unknown words:  14553\n"
     ]
    }
   ],
   "source": [
    "unk_cnt = 0\n",
    "unk_set = set()\n",
    "\n",
    "for word in imdb_encoder.tokens:\n",
    "    embedding_vector = dict_w2v.get(word)\n",
    "\n",
    "    if embedding_vector is not None:\n",
    "        tkn_id = imdb_encoder.encode(word)[0]\n",
    "        embedding_matrix[tkn_id] = embedding_vector\n",
    "    else:\n",
    "        unk_cnt += 1\n",
    "        unk_set.add(word)\n",
    "\n",
    "# Print how many weren't found\n",
    "print(\"Total unknown words: \", unk_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = imdb_encoder.vocab_size # len(chars)\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 64\n",
    "\n",
    "#batch size\n",
    "BATCH_SIZE=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense\n",
    "\n",
    "def build_model_bilstm(vocab_size, embedding_dim, rnn_units, batch_size, train_emb=False):\n",
    "    model = tf.keras.Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, mask_zero=True,\n",
    "    weights=[embedding_matrix], trainable=train_emb),\n",
    "    Bidirectional(LSTM(rnn_units, return_sequences=True, dropout=0.5)),\n",
    "    Bidirectional(LSTM(rnn_units, dropout=0.25)), Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 50)          4696550   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 128)         58880     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 4,854,375\n",
      "Trainable params: 157,825\n",
      "Non-trainable params: 4,696,550\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_fe = build_model_bilstm(\n",
    "    vocab_size = vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "model_fe.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 32s 62ms/step - loss: 0.6346 - accuracy: 0.6290 - precision: 0.6288 - recall: 0.6376\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 18s 70ms/step - loss: 0.5330 - accuracy: 0.7362 - precision: 0.7443 - recall: 0.7208\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 17s 70ms/step - loss: 0.4866 - accuracy: 0.7657 - precision: 0.7716 - recall: 0.7561\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.4677 - accuracy: 0.7760 - precision: 0.7812 - recall: 0.7675\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.4485 - accuracy: 0.7912 - precision: 0.7931 - recall: 0.7889\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.4351 - accuracy: 0.7988 - precision: 0.8040 - recall: 0.7909\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.4209 - accuracy: 0.8088 - precision: 0.8123 - recall: 0.8038\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.4126 - accuracy: 0.8116 - precision: 0.8128 - recall: 0.8104\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.4027 - accuracy: 0.8154 - precision: 0.8167 - recall: 0.8142\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 18s 73ms/step - loss: 0.3979 - accuracy: 0.8187 - precision: 0.8209 - recall: 0.8162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x292eaf57070>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fe.compile(loss='binary_crossentropy',\n",
    "optimizer='adam',\n",
    "metrics=['accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "# Prefetch for performance\n",
    "encoded_train_batched = encoded_train.batch(BATCH_SIZE).prefetch(100)\n",
    "\n",
    "model_fe.fit(encoded_train_batched, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 15s 42ms/step - loss: 0.4265 - accuracy: 0.8293 - precision: 0.7797 - recall: 0.9179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4264746904373169,\n",
       " 0.8292800188064575,\n",
       " 0.7796955704689026,\n",
       " 0.9179199934005737]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fe.evaluate(encoded_test.batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuned GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 50)          4696550   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, None, 128)         58880     \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 4,854,375\n",
      "Trainable params: 4,854,375\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_fe = build_model_bilstm(\n",
    "    vocab_size = vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    train_emb=True)\n",
    "\n",
    "model_fe.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 40s 97ms/step - loss: 0.6139 - accuracy: 0.6427 - precision: 0.6410 - recall: 0.6473\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.4266 - accuracy: 0.8045 - precision: 0.8055 - recall: 0.8039\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.3399 - accuracy: 0.8518 - precision: 0.8514 - recall: 0.8529\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.2875 - accuracy: 0.8807 - precision: 0.8793 - recall: 0.8832\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 0.2455 - accuracy: 0.9013 - precision: 0.9000 - recall: 0.9034\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.2215 - accuracy: 0.9108 - precision: 0.9088 - recall: 0.9136\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 0.1924 - accuracy: 0.9257 - precision: 0.9257 - recall: 0.9260\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 26s 102ms/step - loss: 0.1575 - accuracy: 0.9382 - precision: 0.9362 - recall: 0.9408\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 0.1343 - accuracy: 0.9502 - precision: 0.9518 - recall: 0.9488\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 26s 102ms/step - loss: 0.1150 - accuracy: 0.9573 - precision: 0.9552 - recall: 0.9597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x292eaf1aaf0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fe.compile(loss='binary_crossentropy',\n",
    "optimizer='adam',\n",
    "metrics=['accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "# Prefetch for performance\n",
    "encoded_train_batched = encoded_train.batch(BATCH_SIZE).prefetch(100)\n",
    "\n",
    "model_fe.fit(encoded_train_batched, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 16s 40ms/step - loss: 0.4701 - accuracy: 0.8679 - precision: 0.8793 - recall: 0.8529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47013941407203674,\n",
       " 0.8679199814796448,\n",
       " 0.8793302774429321,\n",
       " 0.8528800010681152]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fe.evaluate(encoded_test.batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "#     def __init__(self, validation = None):   \n",
    "#         super(Metrics, self).__init__()\n",
    "#         self.validation = validation    \n",
    "            \n",
    "#         print('validation shape', len(self.validation[0]))\n",
    "        \n",
    "#     def on_train_begin(self, logs={}):        \n",
    "#         self.val_f1s = []\n",
    "#         self.val_recalls = []\n",
    "#         self.val_precisions = []\n",
    "     \n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         val_targ = self.validation[1]   \n",
    "#         val_predict = (np.asarray(self.model.predict(self.validation[0]))).round()        \n",
    "    \n",
    "#         val_f1 = f1_score(val_targ, val_predict)\n",
    "#         val_recall = recall_score(val_targ, val_predict)         \n",
    "#         val_precision = precision_score(val_targ, val_predict)\n",
    "        \n",
    "#         self.val_f1s.append(round(val_f1, 6))\n",
    "#         self.val_recalls.append(round(val_recall, 6))\n",
    "#         self.val_precisions.append(round(val_precision, 6))\n",
    " \n",
    "#         print(f' â val_f1: {val_f1} â val_precision: {val_precision}, â val_recall: {val_recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fe.compile(loss='binary_crossentropy',\n",
    "optimizer='adam',\n",
    "metrics=['accuracy', 'Precision', 'Recall']) \n",
    "#callbacks=[CustomCallback()])\n",
    "\n",
    "# Prefetch for performance\n",
    "encoded_train_batched = encoded_train.batch(BATCH_SIZE).prefetch(100)\n",
    "\n",
    "model_fe.fit(encoded_train_batched, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fe.evaluate(encoded_test.batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning Pre-trained BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # Verify GPU is detected and working\n",
    "# tf.config.experimental.list_physical_devices()\n",
    "\n",
    "# imdb_train, ds_info = tfds.load(name=\"imdb_reviews\", split=\"train\", with_info=True, as_supervised=True)\n",
    "# imdb_test = tfds.load(name=\"imdb_reviews\", split=\"test\", as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "bert_name = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_name,\n",
    "add_special_tokens=True,\n",
    "do_lower_case=False,\n",
    "max_length=150,\n",
    "pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained(bert_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.encode_plus(\" Don't be lured\", add_special_tokens=True,\n",
    "#                       max_length=9,\n",
    "#                       pad_to_max_length=True,\n",
    "#                       return_attention_mask=True,\n",
    "#                       return_token_type_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.encode_plus(\" Don't be\",\" lured\", add_special_tokens=True,\n",
    "#                       max_length=10,\n",
    "#                       pad_to_max_length=True,\n",
    "#                       return_attention_mask=True,\n",
    "#                       return_token_type_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encoder(review):\n",
    "    txt = review.numpy().decode('utf-8')\n",
    "    encoded = tokenizer.encode_plus(txt, add_special_tokens=True,\n",
    "                                    max_length=150,\n",
    "                                    pad_to_max_length=True,\n",
    "                                    return_attention_mask=True,\n",
    "                                    return_token_type_ids=True)\n",
    "    return encoded['input_ids'], encoded['token_type_ids'], encoded['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\deepl\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2149: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bert_train = [bert_encoder(r) for r, l in imdb_train]\n",
    "bert_lbl = [l for r, l in imdb_train]\n",
    "\n",
    "bert_train = np.array(bert_train)\n",
    "bert_lbl = tf.keras.utils.to_categorical(bert_lbl, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 3, 150) (20000, 2)\n"
     ]
    }
   ],
   "source": [
    "# create training and validation splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(bert_train, \n",
    "                                                  bert_lbl,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=42)\n",
    "\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_reviews, tr_segments, tr_masks = np.split(x_train, 3, axis=1)\n",
    "val_reviews, val_segments, val_masks = np.split(x_val, 3, axis=1)\n",
    "\n",
    "tr_reviews = tr_reviews.squeeze()\n",
    "tr_segments = tr_segments.squeeze()\n",
    "tr_masks = tr_masks.squeeze()\n",
    "\n",
    "val_reviews = val_reviews.squeeze()\n",
    "val_segments = val_segments.squeeze()\n",
    "val_masks = val_masks.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_to_features(input_ids,attention_masks,token_type_ids,y):\n",
    "    return {\"input_ids\": input_ids,\n",
    "          \"attention_mask\": attention_masks,\n",
    "          \"token_type_ids\": token_type_ids},y\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((tr_reviews, tr_masks, \n",
    "                                               tr_segments, y_train)).\\\n",
    "            map(example_to_features).shuffle(100).batch(16)\n",
    "\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((val_reviews, val_masks, \n",
    "                                               val_segments, y_val)).\\\n",
    "            map(example_to_features).shuffle(100).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108310272 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "bert_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning BERT on IMDB\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x00000224F9BE6B80>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x00000224F9BE6B80>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x00000224F9BE6B80>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4203 - accuracy: 0.7963WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 627s 486ms/step - loss: 0.4202 - accuracy: 0.7964 - val_loss: 0.2730 - val_accuracy: 0.8824\n",
      "Epoch 2/3\n",
      "1250/1250 [==============================] - 617s 494ms/step - loss: 0.2130 - accuracy: 0.9144 - val_loss: 0.3182 - val_accuracy: 0.8830\n",
      "Epoch 3/3\n",
      "1250/1250 [==============================] - 625s 500ms/step - loss: 0.1098 - accuracy: 0.9611 - val_loss: 0.4720 - val_accuracy: 0.8714\n"
     ]
    }
   ],
   "source": [
    "print(\"Fine-tuning BERT on IMDB\")\n",
    "\n",
    "bert_history = bert_model.fit(train_ds, epochs=3,validation_data=valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepl\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2149: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# prep data for testing\n",
    "bert_test = [bert_encoder(r) for r,l in imdb_test]\n",
    "bert_tst_lbl = [l for r, l in imdb_test]\n",
    "\n",
    "bert_test2 = np.array(bert_test)\n",
    "bert_tst_lbl2 = tf.keras.utils.to_categorical (bert_tst_lbl,\n",
    "num_classes=2)\n",
    "\n",
    "ts_reviews, ts_segments, ts_masks = np.split(bert_test2, 3, axis=1)\n",
    "ts_reviews = ts_reviews.squeeze()\n",
    "ts_segments = ts_segments.squeeze()\n",
    "ts_masks = ts_masks.squeeze()\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((ts_reviews, ts_masks, ts_segments, bert_tst_lbl2)).\\\n",
    "map(example_to_features).shuffle(100).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 224s 143ms/step - loss: 0.4861 - accuracy: 0.8658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4861351549625397, 0.8657600283622742]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Fine-tuned Pre-trained BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108310272 \n",
      "=================================================================\n",
      "Total params: 108,310,272\n",
      "Trainable params: 108,310,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertModel\n",
    "bert_name = 'bert-base-cased'\n",
    "bert = TFBertModel.from_pretrained(bert_name)\n",
    "bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 150\n",
    "inp_ids = tf.keras.layers.Input((max_seq_len,), dtype=tf.int64,\n",
    "name=\"input_ids\")\n",
    "att_mask = tf.keras.layers.Input((max_seq_len,), dtype=tf.int64,\n",
    "name=\"attention_mask\")\n",
    "seg_ids = tf.keras.layers.Input((max_seq_len,), dtype=tf.int64,\n",
    "name=\"token_type_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': TensorSpec(shape=(None, 150), dtype=tf.int32, name=None),\n",
       "  'attention_mask': TensorSpec(shape=(None, 150), dtype=tf.int32, name=None),\n",
       "  'token_type_ids': TensorSpec(shape=(None, 150), dtype=tf.int32, name=None)},\n",
       " TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TFBaseModelOutputWithPooling(last_hidden_state=<KerasTensor: shape=(None, 150, 768) dtype=float32 (created by layer 'tf_bert_model')>, pooler_output=<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_bert_model')>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_dict = {\"input_ids\": inp_ids,\n",
    "\"attention_mask\": att_mask,\n",
    "\"token_type_ids\": seg_ids}\n",
    "outputs = bert(inp_dict)\n",
    "# let's see the output structure\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Dropout(0.2)(outputs[1])\n",
    "x = tf.keras.layers.Dense(200, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(2, activation='sigmoid')(x)\n",
    "custom_model = tf.keras.models.Model(inputs=inp_dict, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "attention_mask (InputLayer)     [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_ids (InputLayer)          [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_type_ids (InputLayer)     [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 108310272   attention_mask[0][0]             \n",
      "                                                                 input_ids[0][0]                  \n",
      "                                                                 token_type_ids[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 768)          0           tf_bert_model[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 200)          153800      dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 200)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            402         dropout_76[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 108,464,474\n",
      "Trainable params: 108,464,474\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "custom_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Model: Fine-tuning BERT on IMDB\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4720 - accuracy: 0.7647WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 619s 487ms/step - loss: 0.4719 - accuracy: 0.7648 - val_loss: 0.2819 - val_accuracy: 0.8798\n",
      "Epoch 2/3\n",
      "1250/1250 [==============================] - 633s 506ms/step - loss: 0.2380 - accuracy: 0.9078 - val_loss: 0.2812 - val_accuracy: 0.8858\n",
      "Epoch 3/3\n",
      "1250/1250 [==============================] - 628s 502ms/step - loss: 0.1284 - accuracy: 0.9544 - val_loss: 0.3639 - val_accuracy: 0.8884\n"
     ]
    }
   ],
   "source": [
    "print(\"Custom Model: Fine-tuning BERT on IMDB\")\n",
    "\n",
    "custom_history = custom_model.fit(train_ds, epochs=3,validation_data=valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 229s 146ms/step - loss: 0.3923 - accuracy: 0.8805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3923428952693939, 0.8805199861526489]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.evaluate(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
