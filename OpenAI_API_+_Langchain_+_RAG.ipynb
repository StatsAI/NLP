{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM7UausrVLLnzt7ad2U0TCG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StatsAI/NLP/blob/main/OpenAI_API_%2B_Langchain_%2B_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken cohere openai langchain faiss-cpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jpy4mdt9lKJo",
        "outputId": "0ff5947f-16fa-4903-f41f-2fabea6c9b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (4.37)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.3.7)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.348)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.7.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.9.1)\n",
            "Requirement already satisfied: backoff<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.2.1)\n",
            "Requirement already satisfied: fastavro<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.9.1)\n",
            "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (6.8.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-core<0.1,>=0.0.12 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.12)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.69)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.1,>=0.0.12->langchain) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "api_key = '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'\n",
        "\n",
        "client = OpenAI(api_key = api_key)"
      ],
      "metadata": {
        "id": "JsAIVfNrlYyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fabricator-ai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lhv9ZxGilsVp",
        "outputId": "e69a3c03-d385-44a1-a2cf-0301f90852e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fabricator-ai\n",
            "  Downloading fabricator_ai-0.2.0-py3-none-any.whl (23 kB)\n",
            "Collecting datasets (from fabricator-ai)\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting farm-haystack>=1.18.0 (from fabricator-ai)\n",
            "  Downloading farm_haystack-1.22.1-py3-none-any.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.0/856.0 kB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting loguru (from fabricator-ai)\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boilerpy3 (from farm-haystack>=1.18.0->fabricator-ai)\n",
            "  Downloading boilerpy3-1.0.7-py3-none-any.whl (22 kB)\n",
            "Collecting events (from farm-haystack>=1.18.0->fabricator-ai)\n",
            "  Downloading Events-0.5-py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from farm-haystack>=1.18.0->fabricator-ai) (0.25.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from farm-haystack>=1.18.0->fabricator-ai) (4.19.2)\n",
            "Collecting lazy-imports==0.3.1 (from farm-haystack>=1.18.0->fabricator-ai)\n",
            "  Downloading lazy_imports-0.3.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from farm-haystack>=1.18.0->fabricator-ai) (10.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from farm-haystack>=1.18.0->fabricator-ai) (3.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from farm-haystack>=1.18.0->fabricator-ai) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from farm-haystack>=1.18.0->fabricator-ai) (9.4.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from farm-haystack>=1.18.0->fabricator-ai) (4.0.0)\n",
            "Collecting posthog (from farm-haystack>=1.18.0->fabricator-ai)\n",
            "  Downloading posthog-3.1.0-py2.py3-none-any.whl (37 kB)\n",
            "Collecting prompthub-py==4.0.0 (from farm-haystack>=1.18.0->fabricator-ai)\n",
            "  Downloading prompthub_py-4.0.0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack>=1.18.0->fabricator-ai) (1.10.13)\n",
            "Collecting quantulum3 (from farm-haystack>=1.18.0->fabricator-ai)\n",
            "  Downloading quantulum3-0.9.0-py3-none-any.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rank-bm25 (from farm-haystack>=1.18.0->fabricator-ai)\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farm-haystack>=1.18.0->fabricator-ai) (2.31.0)\n",
            "Collecting requests-cache<1.0.0 (from farm-haystack>=1.18.0->fabricator-ai)\n",
            "  Downloading requests_cache-0.9.8-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.7/48.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn>=1.3.0 (from farm-haystack>=1.18.0->fabricator-ai)\n",
            "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sseclient-py (from farm-haystack>=1.18.0->fabricator-ai)\n",
            "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from farm-haystack>=1.18.0->fabricator-ai) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from farm-haystack>=1.18.0->fabricator-ai) (0.5.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farm-haystack>=1.18.0->fabricator-ai) (4.66.1)\n",
            "Collecting transformers==4.34.1 (from farm-haystack>=1.18.0->fabricator-ai)\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from prompthub-py==4.0.0->farm-haystack>=1.18.0->fabricator-ai) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack>=1.18.0->fabricator-ai) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack>=1.18.0->fabricator-ai) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack>=1.18.0->fabricator-ai) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack>=1.18.0->fabricator-ai) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack>=1.18.0->fabricator-ai) (2023.6.3)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers==4.34.1->farm-haystack>=1.18.0->fabricator-ai)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m116.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack>=1.18.0->fabricator-ai) (0.4.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->fabricator-ai) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets->fabricator-ai)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->fabricator-ai)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->fabricator-ai) (3.4.1)\n",
            "Collecting multiprocess (from datasets->fabricator-ai)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->fabricator-ai) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->fabricator-ai) (3.9.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->fabricator-ai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->fabricator-ai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->fabricator-ai) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->fabricator-ai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->fabricator-ai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->fabricator-ai) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.1->farm-haystack>=1.18.0->fabricator-ai) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack>=1.18.0->fabricator-ai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack>=1.18.0->fabricator-ai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack>=1.18.0->fabricator-ai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack>=1.18.0->fabricator-ai) (2023.11.17)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack>=1.18.0->fabricator-ai) (1.4.4)\n",
            "Collecting cattrs>=22.2 (from requests-cache<1.0.0->farm-haystack>=1.18.0->fabricator-ai)\n",
            "  Downloading cattrs-23.2.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting url-normalize>=1.4 (from requests-cache<1.0.0->farm-haystack>=1.18.0->fabricator-ai)\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack>=1.18.0->fabricator-ai) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack>=1.18.0->fabricator-ai) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack>=1.18.0->fabricator-ai) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack>=1.18.0->fabricator-ai) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack>=1.18.0->fabricator-ai) (1.0.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack>=1.18.0->fabricator-ai) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->farm-haystack>=1.18.0->fabricator-ai) (0.14.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack>=1.18.0->fabricator-ai) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack>=1.18.0->fabricator-ai) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack>=1.18.0->fabricator-ai) (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack>=1.18.0->fabricator-ai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack>=1.18.0->fabricator-ai) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack>=1.18.0->fabricator-ai) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog->farm-haystack>=1.18.0->fabricator-ai)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack>=1.18.0->fabricator-ai) (2.2.1)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from quantulum3->farm-haystack>=1.18.0->fabricator-ai) (7.0.0)\n",
            "Collecting num2words (from quantulum3->farm-haystack>=1.18.0->fabricator-ai)\n",
            "  Downloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache<1.0.0->farm-haystack>=1.18.0->fabricator-ai) (1.2.0)\n",
            "INFO: pip is looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers==4.34.1->farm-haystack>=1.18.0->fabricator-ai)\n",
            "  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m123.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from fabricator-ai)\n",
            "  Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.34.1->farm-haystack>=1.18.0->fabricator-ai)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt>=0.6.2 (from num2words->quantulum3->farm-haystack>=1.18.0->fabricator-ai)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=94c493873088d79679bdcbc9b69e64f20d3f2c9b6b471e74acb8f617e89c4c59\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: sseclient-py, monotonic, events, docopt, url-normalize, rank-bm25, pyarrow-hotfix, num2words, loguru, lazy-imports, dill, cattrs, boilerpy3, scikit-learn, requests-cache, prompthub-py, posthog, multiprocess, huggingface-hub, tokenizers, quantulum3, transformers, datasets, farm-haystack, fabricator-ai\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.19.4\n",
            "    Uninstalling huggingface-hub-0.19.4:\n",
            "      Successfully uninstalled huggingface-hub-0.19.4\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed boilerpy3-1.0.7 cattrs-23.2.3 datasets-2.14.7 dill-0.3.7 docopt-0.6.2 events-0.5 fabricator-ai-0.2.0 farm-haystack-1.22.1 huggingface-hub-0.17.3 lazy-imports-0.3.1 loguru-0.7.2 monotonic-1.6 multiprocess-0.70.15 num2words-0.5.13 posthog-3.1.0 prompthub-py-4.0.0 pyarrow-hotfix-0.6 quantulum3-0.9.0 rank-bm25-0.2.2 requests-cache-0.9.8 scikit-learn-1.3.2 sseclient-py-1.8.0 tokenizers-0.14.1 transformers-4.34.1 url-normalize-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"Assume that you are an expert sales person with 20 years of experience that is training sales staff\"},\n",
        "    {\"role\": \"user\", \"content\": \"Create 25 very detailed examples numbered 1-25 consisting of recommendations to junior account executives so they can become better sales reps\"}\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "bCIudr6a1Y46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UivAODkN3Hmm",
        "outputId": "95218b0d-d04e-4fe2-bc71-259d2fc17132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for Junior Account Executives to Become Better Sales Reps:\n",
            "\n",
            "1. Understand the product: Take the time to fully understand the features, benefits, and value proposition of the product or service you are selling. This will help you articulate its value to potential customers effectively.\n",
            "\n",
            "2. Listen actively: Practice active listening during sales conversations to understand customer needs, challenges, and pain points. This will enable you to provide tailored solutions that meet their requirements.\n",
            "\n",
            "3. Build relationships: Focus on building strong relationships with your customers based on trust and mutual respect. This will create a foundation for long-term partnerships and repeat business.\n",
            "\n",
            "4. Keep your promises: Honor commitments made to customers, whether it is delivering on time, providing additional information, or following up promptly. This will enhance your credibility and reputation.\n",
            "\n",
            "5. Be proactive: Don't wait for leads to come to you; actively seek out new opportunities by prospecting and networking. This proactive approach will keep your pipeline healthy and increase your chances of success.\n",
            "\n",
            "6. Be persistent: Sales can be challenging, but persistence is key. Rejection is part of the process, so don't give up easily. Keep following up, refining your approach, and learning from each interaction.\n",
            "\n",
            "7. Practice empathy: Put yourself in your customers' shoes to understand their perspective, challenges, and goals. This will enable you to offer solutions that genuinely address their needs.\n",
            "\n",
            "8. Learn from successful colleagues: Observe and learn from top-performing sales professionals in your organization. Study their techniques, strategies, and approaches to gain insight into what works.\n",
            "\n",
            "9. Polish your communication skills: Invest in improving your verbal and written communication skills. The ability to clearly and effectively convey your ideas and recommendations can make a significant difference in closing deals.\n",
            "\n",
            "10. Be organized: Stay on top of your sales activities and maintain a structured approach. Use tools like CRM software to track leads, manage tasks, and prioritize your workload for maximum efficiency.\n",
            "\n",
            "11. Continuously learn: Sales is an ever-evolving field, so commit to continuous learning. Attend industry conferences, read books, listen to podcasts, and take courses to stay updated with the latest trends and techniques.\n",
            "\n",
            "12. Understand your competition: Research and analyze your competitors to identify their strengths, weaknesses, and differentiators. This knowledge will help you position your product or service effectively.\n",
            "\n",
            "13. Deliver exceptional customer service: Go the extra mile to provide outstanding customer service. Respond promptly to inquiries, provide support whenever needed, and resolve issues promptly to create loyal customers.\n",
            "\n",
            "14. Collaborate with other teams: Sales doesn't happen in isolation; collaborate with marketing, customer success, and other teams to align your efforts. This collaborative approach will enable you to deliver a seamless customer experience.\n",
            "\n",
            "15. Focus on value: Instead of just pushing for a sale, focus on the value that your product or service brings to the customer. Help them see the return on investment and how it can positively impact their business.\n",
            "\n",
            "16. Develop a strong personal brand: Invest in building your personal brand as a trusted and knowledgeable sales professional. This includes having a strong online presence, sharing valuable insights, and cultivating a positive reputation.\n",
            "\n",
            "17. Understand the buying process: Familiarize yourself with the buying process your customers typically go through. This will help you anticipate their needs and guide them seamlessly through each stage of the sales cycle.\n",
            "\n",
            "18. Analyze and learn from failures: Don't be discouraged by failures or lost deals. Instead, take the time to analyze what went wrong, where improvements could be made, and apply these learnings in future sales interactions.\n",
            "\n",
            "19. Develop storytelling abilities: Learn to weave compelling stories around your product or service to engage customers on an emotional level. Stories are memorable and can help differentiate you from competitors.\n",
            "\n",
            "20. Adapt to different personalities: Each customer you encounter has a unique personality and communication style. Adapt your approach to best connect with them, whether it's through humor, data-driven insights, or personal anecdotes.\n",
            "\n",
            "21. Be confident but not pushy: Confidence is crucial in sales, but avoid crossing the line into pushiness. Focus on building trust and providing valuable solutions rather than applying unnecessary pressure on customers.\n",
            "\n",
            "22. Practice time management: Effectively manage your time by prioritizing tasks, setting realistic goals, and avoiding distractions. This will help you stay focused and make the most of your workday.\n",
            "\n",
            "23. Develop negotiation skills: Negotiation is an integral part of sales. Learn effective negotiation techniques to ensure both you and your customer get the best deal possible, while building a mutually beneficial relationship.\n",
            "\n",
            "24. Seek feedback and learn from it: Actively seek feedback from your colleagues, managers, and customers to identify areas for improvement. Use this feedback to refine your sales approach and enhance your overall performance.\n",
            "\n",
            "25. Take care of yourself: Sales can be demanding, so prioritize self-care. Maintain a healthy work-life balance, practice stress management techniques, pursue hobbies, and invest in personal development to stay motivated and energized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = response.choices[0].message.content\n",
        "\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "xUuudRX48NBC",
        "outputId": "b9f9ca2e-724b-42ef-a4f1-cfe19f1a8a7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Recommendations for Junior Account Executives to Become Better Sales Reps:\\n\\n1. Understand the product: Take the time to fully understand the features, benefits, and value proposition of the product or service you are selling. This will help you articulate its value to potential customers effectively.\\n\\n2. Listen actively: Practice active listening during sales conversations to understand customer needs, challenges, and pain points. This will enable you to provide tailored solutions that meet their requirements.\\n\\n3. Build relationships: Focus on building strong relationships with your customers based on trust and mutual respect. This will create a foundation for long-term partnerships and repeat business.\\n\\n4. Keep your promises: Honor commitments made to customers, whether it is delivering on time, providing additional information, or following up promptly. This will enhance your credibility and reputation.\\n\\n5. Be proactive: Don't wait for leads to come to you; actively seek out new opportunities by prospecting and networking. This proactive approach will keep your pipeline healthy and increase your chances of success.\\n\\n6. Be persistent: Sales can be challenging, but persistence is key. Rejection is part of the process, so don't give up easily. Keep following up, refining your approach, and learning from each interaction.\\n\\n7. Practice empathy: Put yourself in your customers' shoes to understand their perspective, challenges, and goals. This will enable you to offer solutions that genuinely address their needs.\\n\\n8. Learn from successful colleagues: Observe and learn from top-performing sales professionals in your organization. Study their techniques, strategies, and approaches to gain insight into what works.\\n\\n9. Polish your communication skills: Invest in improving your verbal and written communication skills. The ability to clearly and effectively convey your ideas and recommendations can make a significant difference in closing deals.\\n\\n10. Be organized: Stay on top of your sales activities and maintain a structured approach. Use tools like CRM software to track leads, manage tasks, and prioritize your workload for maximum efficiency.\\n\\n11. Continuously learn: Sales is an ever-evolving field, so commit to continuous learning. Attend industry conferences, read books, listen to podcasts, and take courses to stay updated with the latest trends and techniques.\\n\\n12. Understand your competition: Research and analyze your competitors to identify their strengths, weaknesses, and differentiators. This knowledge will help you position your product or service effectively.\\n\\n13. Deliver exceptional customer service: Go the extra mile to provide outstanding customer service. Respond promptly to inquiries, provide support whenever needed, and resolve issues promptly to create loyal customers.\\n\\n14. Collaborate with other teams: Sales doesn't happen in isolation; collaborate with marketing, customer success, and other teams to align your efforts. This collaborative approach will enable you to deliver a seamless customer experience.\\n\\n15. Focus on value: Instead of just pushing for a sale, focus on the value that your product or service brings to the customer. Help them see the return on investment and how it can positively impact their business.\\n\\n16. Develop a strong personal brand: Invest in building your personal brand as a trusted and knowledgeable sales professional. This includes having a strong online presence, sharing valuable insights, and cultivating a positive reputation.\\n\\n17. Understand the buying process: Familiarize yourself with the buying process your customers typically go through. This will help you anticipate their needs and guide them seamlessly through each stage of the sales cycle.\\n\\n18. Analyze and learn from failures: Don't be discouraged by failures or lost deals. Instead, take the time to analyze what went wrong, where improvements could be made, and apply these learnings in future sales interactions.\\n\\n19. Develop storytelling abilities: Learn to weave compelling stories around your product or service to engage customers on an emotional level. Stories are memorable and can help differentiate you from competitors.\\n\\n20. Adapt to different personalities: Each customer you encounter has a unique personality and communication style. Adapt your approach to best connect with them, whether it's through humor, data-driven insights, or personal anecdotes.\\n\\n21. Be confident but not pushy: Confidence is crucial in sales, but avoid crossing the line into pushiness. Focus on building trust and providing valuable solutions rather than applying unnecessary pressure on customers.\\n\\n22. Practice time management: Effectively manage your time by prioritizing tasks, setting realistic goals, and avoiding distractions. This will help you stay focused and make the most of your workday.\\n\\n23. Develop negotiation skills: Negotiation is an integral part of sales. Learn effective negotiation techniques to ensure both you and your customer get the best deal possible, while building a mutually beneficial relationship.\\n\\n24. Seek feedback and learn from it: Actively seek feedback from your colleagues, managers, and customers to identify areas for improvement. Use this feedback to refine your sales approach and enhance your overall performance.\\n\\n25. Take care of yourself: Sales can be demanding, so prioritize self-care. Maintain a healthy work-life balance, practice stress management techniques, pursue hobbies, and invest in personal development to stay motivated and energized.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LangChain + RAG"
      ],
      "metadata": {
        "id": "P2-su0LL5Gpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
        "from langchain.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "TU7MKijItLx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    deployment=\"gpt-3.5-turbo\"\n",
        ")\n",
        "\n",
        "vectorstore = FAISS.from_texts(data, embedding=embeddings)\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "ygTfKNTUri4Y",
        "outputId": "d920c19d-83c9-40ba-cace-682843cf8983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-ec74cb9ba92d>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mvectorstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mretriever\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_retriever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/faiss.py\u001b[0m in \u001b[0;36mfrom_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    909\u001b[0m                 \u001b[0mfaiss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \"\"\"\n\u001b[0;32m--> 911\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m         return cls.__from(\n\u001b[1;32m    913\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/embeddings/openai.py\u001b[0m in \u001b[0;36membed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;31m#       than the maximum context and use length-safe embedding function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeployment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_len_safe_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     async def aembed_documents(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/embeddings/openai.py\u001b[0m in \u001b[0;36m_get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mbatched_embeddings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m             response = embed_with_retry(\n\u001b[0m\u001b[1;32m    496\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_chunk_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/embeddings/openai.py\u001b[0m in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;34m\"\"\"Use tenacity to retry the embedding call.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_openai_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0mretry_decorator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_retry_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/embeddings.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, input, model, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0;34m\"/embeddings\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaybe_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_create_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbeddingCreateParams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         )\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 856\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m    895\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m    895\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-ada-002 in organization org-J7ppSri4zaXm2WrcavpfJdQE on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How its supposed to work!"
      ],
      "metadata": {
        "id": "XAa7NXuj8-tr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XV5BGduJ8-rM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = FAISS.from_texts(\n",
        "    [\"harrison worked at kensho\"], embedding=OpenAIEmbeddings()\n",
        ")\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "model = ChatOpenAI()"
      ],
      "metadata": {
        "id": "gqqjeqTn87c-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "L-TkyipTw2t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"where did harrison work?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kGjyB3aAn9S0",
        "outputId": "386670f8-0a70-41f8-ba23-d0a90964edcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Harrison worked at Kensho.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XRAKIE1Y8BaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aUm07tq98BKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXTRAS"
      ],
      "metadata": {
        "id": "gls_gzKK43-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from haystack.nodes import PromptNode\n",
        "from fabricator import DatasetGenerator\n",
        "from fabricator.prompts import BasePrompt\n",
        "\n",
        "\n",
        "prompt = BasePrompt(\n",
        "    task_description=\"Assume that you are an expert sales person that is training sales staff. Create 25 very detailed examples numbered 1-25 consisting of recommendations to junior account executives so they can become better sales reps.\",\n",
        ")\n",
        "\n",
        "prompt_node = PromptNode(\n",
        "    model_name_or_path=\"gpt-3.5-turbo\",\n",
        "    api_key= api_key,\n",
        "    #max_length=100,\n",
        ")\n",
        "\n",
        "generator = DatasetGenerator(prompt_node)\n",
        "generated_dataset = generator.generate(\n",
        "    prompt_template=prompt,\n",
        "    #max_prompt_calls=10,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaYvyeQpmveo",
        "outputId": "7f7e3d59-ea96-47ed-dd1d-430b4d2063a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2023-12-08 19:08:26.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfabricator.prompts.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1m\n",
            "The prompt to the LLM will be like:\n",
            "----------\n",
            "Assume that you are an expert sales person that is training sales staff. Create 25 very detailed examples numbered 1-25 consisting of recommendations to junior account executives so they can become better sales reps.\n",
            "\n",
            "text: \n",
            "----------\u001b[0m\n",
            "Generating dataset:   0%|          | 0/10 [00:00<?, ?it/s]WARNING:haystack.utils.openai_utils:1 out of the 1 completions have been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n",
            "Generating dataset:  10%|█         | 1/10 [00:03<00:35,  3.90s/it]WARNING:haystack.utils.openai_utils:1 out of the 1 completions have been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n",
            "Generating dataset:  20%|██        | 2/10 [00:07<00:30,  3.77s/it]WARNING:haystack.utils.openai_utils:1 out of the 1 completions have been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n",
            "Generating dataset:  30%|███       | 3/10 [00:11<00:26,  3.79s/it]WARNING:haystack.utils.openai_utils:1 out of the 1 completions have been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n",
            "Generating dataset:  40%|████      | 4/10 [00:25<00:46,  7.68s/it]WARNING:haystack.utils.openai_utils:1 out of the 1 completions have been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n",
            "Generating dataset:  50%|█████     | 5/10 [00:59<01:26, 17.28s/it]WARNING:haystack.utils.openai_utils:1 out of the 1 completions have been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n",
            "Generating dataset:  60%|██████    | 6/10 [01:13<01:04, 16.23s/it]WARNING:haystack.utils.openai_utils:1 out of the 1 completions have been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n",
            "Generating dataset:  70%|███████   | 7/10 [01:27<00:46, 15.62s/it]WARNING:haystack.utils.openai_utils:1 out of the 1 completions have been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n",
            "Generating dataset:  80%|████████  | 8/10 [02:02<00:43, 21.67s/it]WARNING:haystack.utils.openai_utils:1 out of the 1 completions have been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n",
            "Generating dataset:  90%|█████████ | 9/10 [02:06<00:16, 16.05s/it]WARNING:haystack.utils.openai_utils:1 out of the 1 completions have been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n",
            "\u001b[32m2023-12-08 19:11:06.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfabricator.dataset_generator\u001b[0m:\u001b[36m_inner_generate_loop\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mReached maximum number of prompt calls (10).\u001b[0m\n",
            "Generating dataset:  90%|█████████ | 9/10 [02:40<00:17, 17.82s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orNLJJkd27d1",
        "outputId": "df9a5cef-9735-4a45-d3d4-b3712a157557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Config',\n",
              " '__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__class_vars__',\n",
              " '__config__',\n",
              " '__custom_root_type__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__exclude_fields__',\n",
              " '__fields__',\n",
              " '__fields_set__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__get_validators__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__include_fields__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__json_encoder__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__post_root_validators__',\n",
              " '__pre_root_validators__',\n",
              " '__pretty__',\n",
              " '__private_attributes__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__repr_args__',\n",
              " '__repr_name__',\n",
              " '__repr_str__',\n",
              " '__rich_repr__',\n",
              " '__schema_cache__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__signature__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__try_update_forward_refs__',\n",
              " '__validators__',\n",
              " '_abc_impl',\n",
              " '_calculate_keys',\n",
              " '_copy_and_set_values',\n",
              " '_decompose_class',\n",
              " '_enforce_dict_if_root',\n",
              " '_get_value',\n",
              " '_init_private_attributes',\n",
              " '_iter',\n",
              " 'choices',\n",
              " 'construct',\n",
              " 'copy',\n",
              " 'created',\n",
              " 'dict',\n",
              " 'from_orm',\n",
              " 'id',\n",
              " 'json',\n",
              " 'model',\n",
              " 'model_construct',\n",
              " 'model_dump',\n",
              " 'model_dump_json',\n",
              " 'model_fields_set',\n",
              " 'object',\n",
              " 'parse_file',\n",
              " 'parse_obj',\n",
              " 'parse_raw',\n",
              " 'schema',\n",
              " 'schema_json',\n",
              " 'system_fingerprint',\n",
              " 'update_forward_refs',\n",
              " 'usage',\n",
              " 'validate']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_dataset.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN10jeVYoaod",
        "outputId": "8ad8a566-137d-42b2-df69-345a0eedfca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InMemoryTable\n",
              "text: string\n",
              "----\n",
              "text: [[\"1. Understand your product inside and out: Take the time to learn everything there is to know about the product or service you are selling. This will enable you to confidently answer any questions and address any concerns that potential customers may have.\n",
              "\n",
              "2. Research your target market: Before approaching a potential customer, conduct thorough research to understand their needs, preferences, and pain points. This will allow you to tailor your pitch and offer solutions that are relevant to their specific situation.\n",
              "\n",
              "3. Develop strong communication skills:\",\"1. Establish a strong rapport with your clients by actively listening to their needs and concerns. Show genuine interest in their business and ask thoughtful questions to understand their pain points.\n",
              "\n",
              "2. Always be prepared before a client meeting or sales call. Research the prospect's industry, competitors, and any recent developments that could impact their business. This will help you tailor your pitch and showcase your expertise.\n",
              "\n",
              "3. Develop a deep understanding of your product or service. Know its features, benefits, and how it can solve\",\"1. Understand your product or service inside out: Take the time to thoroughly learn about the features, benefits, and unique selling points of what you're selling. This knowledge will help you confidently address customer queries and effectively highlight the value proposition.\n",
              "\n",
              "2. Build strong relationships with your clients: Sales is not just about closing deals; it's about building long-term relationships. Take the time to understand your clients' needs, goals, and challenges, and provide personalized solutions that add value to their business.\n",
              "\n",
              "3\",\"1. Always prioritize building a strong relationship with your clients. Take the time to understand their needs, concerns, and goals. This will enable you to tailor your sales approach and provide personalized solutions.\n",
              "\n",
              "2. Research your prospects thoroughly before engaging with them. This will help you identify their pain points and challenges, allowing you to position your product or service as the perfect solution.\n",
              "\n",
              "3. Develop a deep understanding of your product or service. Be knowledgeable about its features, benefits, and competitive advantages. This will\",\"1. Always prioritize building relationships with your clients. Take the time to understand their needs, goals, and challenges, and tailor your sales approach accordingly. \n",
              "\n",
              "2. Research your prospects thoroughly before any meeting or call. Familiarize yourself with their industry, competitors, and recent news to showcase your expertise and credibility.\n",
              "\n",
              "3. Practice active listening during sales conversations. Let the prospect speak without interruption, ask relevant questions to show your interest, and reflect back on their key pain points to demonstrate empathy.\n",
              "\n",
              "4\",\"Recommendation 1: Always be prepared before meeting with a potential client. Research their industry, competitors, and any recent news that could impact their business. This will help you understand their needs and position your product or service effectively.\n",
              "\n",
              "Recommendation 2: Develop a strong understanding of your product or service. Know its features, benefits, and how it solves your client's pain points. This knowledge will boost your confidence and enable you to answer any questions or objections effectively.\n",
              "\n",
              "Recommendation 3: Practice\",\"1. Develop a deep understanding of your product or service: Take the time to thoroughly learn about the features, benefits, and unique selling points of what you're selling. This knowledge will enable you to confidently and effectively communicate with potential customers.\n",
              "\n",
              "2. Know your target market: Conduct thorough market research to identify who your ideal customers are. Understand their needs, preferences, and pain points so that you can tailor your sales pitch accordingly.\n",
              "\n",
              "3. Listen actively: When engaging with prospects, focus on listening attent\",\"Recommendations to Junior Account Executives for Becoming Better Sales Reps:\n",
              "\n",
              "1. Develop a deep understanding of your product or service, including its features, benefits, and competitive advantages. This will help you effectively communicate its value to potential customers.\n",
              "\n",
              "2. Prioritize building strong relationships with your clients. Invest time in understanding their needs, challenges, and goals. This will enable you to tailor your sales approach and provide personalized solutions.\n",
              "\n",
              "3. Actively listen to your prospects. Pay attention to their\",\"1. Build relationships with your clients: Take the time to understand their needs and establish trust. This will not only result in repeat business but also referrals.\n",
              "\n",
              "2. Research your prospects: Before reaching out to potential clients, gather as much information as possible about their industry, company, and key decision-makers. This will demonstrate your credibility and help you tailor your pitch effectively.\n",
              "\n",
              "3. Listen more than you speak: Understand that selling is not about pushing your product or service but rather about solving your client's\",\"1. Understand your product or service inside out. Know its features, benefits, and how it solves customer problems. This knowledge will help you confidently answer any questions and position your offering effectively.\n",
              "\n",
              "2. Research your target audience extensively. Understand their needs, pain points, and motivations. This will enable you to tailor your pitch and communicate how your product can add value specifically for them.\n",
              "\n",
              "3. Develop excellent listening skills. Truly understand what your prospects are saying, and ask probing questions to uncover their underlying needs\"]]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}